#!/usr/bin/env python3
"""
AIå¤šæ™ºèƒ½ä½“å·¥ä½œæµå¹³å° - Streamlitç‰ˆæœ¬
GitHubéƒ¨ç½²å‹å¥½çš„å•æ–‡ä»¶åº”ç”¨
"""

import streamlit as st
import requests
import json
import time
import uuid
import os
import tempfile
import base64
from datetime import datetime
from typing import Dict, List, Optional, Any
import io
from PIL import Image

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AIå¤šæ™ºèƒ½ä½“å·¥ä½œæµå¹³å°",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #2E86AB;
        margin-bottom: 2rem;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .user-message {
        background-color: #E3F2FD;
        margin-left: 2rem;
    }
    .assistant-message {
        background-color: #F5F5F5;
        margin-right: 2rem;
    }
    .status-card {
        background-color: #F8F9FA;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #2E86AB;
    }
    .metric-card {
        background-color: #FFFFFF;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

# LLMæœåŠ¡ç±»
class LLMService:
    def __init__(self):
        self.providers = {
            'mock': {'name': 'æœ¬åœ°æ¨¡æ‹Ÿ', 'needsKey': False},
            'openai': {'name': 'OpenAI GPT', 'needsKey': True, 'url': 'https://api.openai.com/v1/chat/completions'},
            'deepseek': {'name': 'DeepSeek', 'needsKey': True, 'url': 'https://api.aimlapi.com/v1/chat/completions'},
            'qianwen': {'name': 'é€šä¹‰åƒé—®', 'needsKey': True, 'url': 'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation'},
        }
    
    async def generate_response(self, message: str, provider: str, api_key: str = None, history: List = None) -> Dict:
        """ç”ŸæˆAIå›å¤"""
        if provider == 'mock':
            return self._mock_response(message)
        
        if not api_key and self.providers[provider]['needsKey']:
            return {"error": "éœ€è¦APIå¯†é’¥"}
        
        try:
            if provider == 'openai':
                return await self._call_openai(message, api_key, history or [])
            elif provider == 'deepseek':
                return await self._call_deepseek(message, api_key, history or [])
            elif provider == 'qianwen':
                return await self._call_qianwen(message, api_key, history or [])
        except Exception as e:
            return {"error": f"APIè°ƒç”¨å¤±è´¥: {str(e)}"}
    
    def _mock_response(self, message: str) -> Dict:
        """æ¨¡æ‹Ÿå›å¤"""
        message_lower = message.lower()
        
        if any(word in message_lower for word in ["å›¾ç‰‡", "å›¾åƒ", "ç…§ç‰‡", "ocr"]):
            return {
                "content": "æˆ‘çœ‹åˆ°æ‚¨æåˆ°äº†å›¾åƒå¤„ç†éœ€æ±‚ã€‚æˆ‘å¯ä»¥å¸®æ‚¨ä½¿ç”¨OCRæŠ€æœ¯è¯†åˆ«å›¾åƒä¸­çš„æ–‡å­—ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ã€‚è¯·ä¸Šä¼ æ‚¨çš„å›¾åƒæ–‡ä»¶ã€‚",
                "suggestions": ["ä¸Šä¼ å›¾åƒæ–‡ä»¶", "æŸ¥çœ‹OCRæœåŠ¡è¯¦æƒ…", "è·å–æŠ¥ä»·"]
            }
        elif any(word in message_lower for word in ["è¯­éŸ³", "éŸ³é¢‘", "tts"]):
            return {
                "content": "æˆ‘äº†è§£æ‚¨éœ€è¦æ–‡æœ¬è½¬è¯­éŸ³æœåŠ¡ã€‚æˆ‘å¯ä»¥å°†æ‚¨çš„æ–‡æœ¬è½¬æ¢ä¸ºé«˜è´¨é‡çš„è¯­éŸ³æ–‡ä»¶ã€‚è¯·è¾“å…¥æ‚¨è¦è½¬æ¢çš„æ–‡æœ¬å†…å®¹ã€‚",
                "suggestions": ["è¾“å…¥æ–‡æœ¬å†…å®¹", "é€‰æ‹©è¯­éŸ³ç±»å‹", "è¯•å¬è¯­éŸ³æ ·æœ¬"]
            }
        else:
            return {
                "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯AIå·¥ä½œæµå¹³å°çš„æ™ºèƒ½åŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®æ‚¨å¤„ç†ï¼š\n\nğŸ–¼ï¸ **å›¾åƒæ–‡å­—è¯†åˆ«**ï¼šå°†å›¾ç‰‡ä¸­çš„æ–‡å­—è½¬æ¢ä¸ºMarkdownæ ¼å¼\nğŸ”Š **æ–‡æœ¬è½¬è¯­éŸ³**ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºé«˜è´¨é‡è¯­éŸ³æ–‡ä»¶\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ã€‚",
                "suggestions": ["ä¸Šä¼ å›¾åƒæ–‡ä»¶", "è¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬", "æŸ¥çœ‹æœåŠ¡ä»·æ ¼"]
            }
    
    async def _call_openai(self, message: str, api_key: str, history: List) -> Dict:
        """è°ƒç”¨OpenAI API"""
        messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAIå·¥ä½œæµå¹³å°çš„åŠ©æ‰‹ï¼Œä¸“é—¨å¤„ç†OCRå’ŒTTSä»»åŠ¡ã€‚"}]
        messages.extend(history)
        messages.append({"role": "user", "content": message})
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "gpt-3.5-turbo",
            "messages": messages,
            "max_tokens": 1000,
            "temperature": 0.7
        }
        
        response = requests.post(self.providers['openai']['url'], headers=headers, json=data)
        
        if response.status_code == 200:
            result = response.json()
            return {"content": result['choices'][0]['message']['content']}
        else:
            return {"error": f"OpenAI APIé”™è¯¯: {response.status_code}"}
    
    async def _call_deepseek(self, message: str, api_key: str, history: List) -> Dict:
        """è°ƒç”¨DeepSeek API"""
        messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAIå·¥ä½œæµå¹³å°çš„åŠ©æ‰‹ï¼Œä¸“é—¨å¤„ç†OCRå’ŒTTSä»»åŠ¡ã€‚"}]
        messages.extend(history)
        messages.append({"role": "user", "content": message})
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "deepseek-chat",
            "messages": messages,
            "max_tokens": 1000,
            "temperature": 0.7
        }
        
        response = requests.post(self.providers['deepseek']['url'], headers=headers, json=data)
        
        if response.status_code == 200:
            result = response.json()
            return {"content": result['choices'][0]['message']['content']}
        else:
            return {"error": f"DeepSeek APIé”™è¯¯: {response.status_code}"}

# TTSæœåŠ¡ç±»
class TTSService:
    def __init__(self):
        self.voices = {
            "21m00Tcm4TlvDq8ikWAM": "Rachel - è‹±è¯­å¥³å£°",
            "AZnzlk1XvdvUeBnXmlld": "Domi - è‹±è¯­å¥³å£°", 
            "EXAVITQu4vr4xnSDxMaL": "Bella - è‹±è¯­å¥³å£°",
            "ErXwobaYiN019PkySvjV": "Antoni - è‹±è¯­ç”·å£°",
            "MF3mGyEYCl7XYWbV9V6O": "Elli - è‹±è¯­å¥³å£°",
            "TxGEqnHWrfWFTfGW9XjX": "Josh - è‹±è¯­ç”·å£°"
        }
    
    def generate_tts_mock(self, text: str, voice_id: str = "21m00Tcm4TlvDq8ikWAM") -> Dict:
        """æ¨¡æ‹ŸTTSç”Ÿæˆ"""
        return {
            "task_id": str(uuid.uuid4()),
            "status": "completed",
            "text": text,
            "voice_id": voice_id,
            "voice_name": self.voices.get(voice_id, "æœªçŸ¥è¯­éŸ³"),
            "duration": len(text) * 0.1,
            "file_size": len(text) * 100,
            "qc_report": {
                "score": 92.5,
                "audio_quality": 90.0,
                "text_accuracy": 95.0,
                "voice_consistency": 88.0,
                "issues": [],
                "recommendations": ["è¯­éŸ³è´¨é‡ä¼˜ç§€"]
            }
        }
    
    def generate_tts_with_elevenlabs(self, text: str, voice_id: str, api_key: str) -> Dict:
        """ä½¿ç”¨ElevenLabs APIç”ŸæˆTTS"""
        if not api_key:
            return {"error": "éœ€è¦ElevenLabs APIå¯†é’¥"}
        
        url = "https://api.elevenlabs.io/v1/text-to-speech/" + voice_id
        headers = {
            "xi-api-key": api_key,
            "Content-Type": "application/json"
        }
        
        data = {
            "text": text,
            "model_id": "eleven_multilingual_v2",
            "voice_settings": {
                "stability": 0.5,
                "similarity_boost": 0.75,
                "style": 0.0,
                "use_speaker_boost": True
            }
        }
        
        try:
            response = requests.post(url, headers=headers, json=data)
            if response.status_code == 200:
                return {
                    "task_id": str(uuid.uuid4()),
                    "status": "completed",
                    "audio_data": response.content,
                    "content_type": "audio/mpeg"
                }
            else:
                return {"error": f"ElevenLabs APIé”™è¯¯: {response.status_code}"}
        except Exception as e:
            return {"error": f"TTSç”Ÿæˆå¤±è´¥: {str(e)}"}

# OCRæœåŠ¡ç±»
class OCRService:
    def __init__(self):
        pass
    
    def extract_text_mock(self, image_data: bytes) -> Dict:
        """æ¨¡æ‹ŸOCRæ–‡å­—æå–"""
        return {
            "task_id": str(uuid.uuid4()),
            "status": "completed",
            "extracted_text": "è¿™æ˜¯ä»å›¾åƒä¸­æå–çš„ç¤ºä¾‹æ–‡æœ¬å†…å®¹ã€‚\n\n## è¯†åˆ«ç»“æœ\n\nå®é™…é¡¹ç›®ä¸­ï¼Œè¿™é‡Œä¼šæ˜¾ç¤ºOCRè¯†åˆ«å‡ºçš„çœŸå®æ–‡æœ¬å†…å®¹ï¼Œå¹¶æ ¼å¼åŒ–ä¸ºMarkdownæ ¼å¼ã€‚",
            "confidence": 0.95,
            "qc_report": {
                "score": 88.0,
                "text_quality": 90.0,
                "image_quality": 85.0,
                "recognition_accuracy": 92.0,
                "issues": ["éƒ¨åˆ†å­—ç¬¦ç½®ä¿¡åº¦è¾ƒä½"],
                "recommendations": ["å»ºè®®æé«˜å›¾åƒåˆ†è¾¨ç‡"]
            }
        }

# åˆå§‹åŒ–æœåŠ¡
@st.cache_resource
def get_services():
    return {
        'llm': LLMService(),
        'tts': TTSService(),
        'ocr': OCRService()
    }

def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    services = get_services()
    
    # é¡µé¢æ ‡é¢˜
    st.markdown("<h1 class='main-header'>ğŸ¤– AIå¤šæ™ºèƒ½ä½“å·¥ä½œæµå¹³å°</h1>", unsafe_allow_html=True)
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®è®¾ç½®")
        
        # LLMé…ç½®
        st.subheader("ğŸ§  AIæ¨¡å‹è®¾ç½®")
        llm_provider = st.selectbox(
            "é€‰æ‹©AIæœåŠ¡æä¾›å•†",
            options=list(services['llm'].providers.keys()),
            format_func=lambda x: services['llm'].providers[x]['name']
        )
        
        llm_api_key = ""
        if services['llm'].providers[llm_provider]['needsKey']:
            llm_api_key = st.text_input(
                "APIå¯†é’¥", 
                type="password",
                help=f"è¯·è¾“å…¥{services['llm'].providers[llm_provider]['name']}çš„APIå¯†é’¥"
            )
        
        # TTSé…ç½®
        st.subheader("ğŸµ è¯­éŸ³åˆæˆè®¾ç½®")
        use_elevenlabs = st.checkbox("ä½¿ç”¨ElevenLabs TTS", help="éœ€è¦ElevenLabs APIå¯†é’¥")
        
        elevenlabs_api_key = ""
        if use_elevenlabs:
            elevenlabs_api_key = st.text_input(
                "ElevenLabs APIå¯†é’¥",
                type="password"
            )
        
        voice_id = st.selectbox(
            "é€‰æ‹©è¯­éŸ³",
            options=list(services['tts'].voices.keys()),
            format_func=lambda x: services['tts'].voices[x]
        )
        
        # æ¸…é™¤èŠå¤©å†å²
        if st.button("ğŸ—‘ï¸ æ¸…é™¤èŠå¤©å†å²"):
            st.session_state.messages = []
            st.rerun()
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "project_data" not in st.session_state:
        st.session_state.project_data = {
            "files": [],
            "quotes": [],
            "tasks": []
        }
    
    # ä¸»ç•Œé¢ä¸‰åˆ—å¸ƒå±€
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        st.header("ğŸ’¬ æ™ºèƒ½å¯¹è¯")
        
        # æ˜¾ç¤ºèŠå¤©å†å²
        chat_container = st.container()
        with chat_container:
            for message in st.session_state.messages:
                if message["role"] == "user":
                    st.markdown(f"""
                    <div class="chat-message user-message">
                        <strong>ğŸ‘¤ æ‚¨:</strong><br>
                        {message["content"]}
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div class="chat-message assistant-message">
                        <strong>ğŸ¤– åŠ©æ‰‹:</strong><br>
                        {message["content"]}
                    </div>
                    """, unsafe_allow_html=True)
        
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader(
            "ğŸ“ ä¸Šä¼ å›¾åƒæ–‡ä»¶ (OCR)",
            type=['png', 'jpg', 'jpeg', 'pdf'],
            help="æ”¯æŒPNGã€JPGã€JPEGã€PDFæ ¼å¼"
        )
        
        if uploaded_file is not None:
            # æ˜¾ç¤ºä¸Šä¼ çš„å›¾åƒ
            if uploaded_file.type.startswith('image'):
                st.image(uploaded_file, caption="ä¸Šä¼ çš„å›¾åƒ", use_column_width=True)
            
            if st.button("ğŸ” å¼€å§‹OCRè¯†åˆ«"):
                with st.spinner("æ­£åœ¨è¯†åˆ«å›¾åƒä¸­çš„æ–‡å­—..."):
                    # å¤„ç†OCR
                    image_data = uploaded_file.read()
                    ocr_result = services['ocr'].extract_text_mock(image_data)
                    
                    if ocr_result["status"] == "completed":
                        st.session_state.project_data["files"].append({
                            "type": "ocr",
                            "filename": uploaded_file.name,
                            "result": ocr_result
                        })
                        
                        # æ·»åŠ åˆ°èŠå¤©å†å²
                        st.session_state.messages.append({
                            "role": "user",
                            "content": f"ä¸Šä¼ äº†å›¾åƒæ–‡ä»¶: {uploaded_file.name}"
                        })
                        st.session_state.messages.append({
                            "role": "assistant", 
                            "content": f"âœ… OCRè¯†åˆ«å®Œæˆï¼\n\n**è¯†åˆ«ç»“æœ:**\n{ocr_result['extracted_text']}\n\n**è´¨é‡è¯„åˆ†:** {ocr_result['qc_report']['score']}/100"
                        })
                        st.rerun()
        
        # èŠå¤©è¾“å…¥
        user_input = st.text_input("ğŸ’­ è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–éœ€æ±‚:", key="chat_input")
        
        if st.button("å‘é€", key="send_message") and user_input:
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            st.session_state.messages.append({"role": "user", "content": user_input})
            
            # ç”ŸæˆAIå›å¤
            with st.spinner("AIæ­£åœ¨æ€è€ƒ..."):
                history = [{"role": msg["role"], "content": msg["content"]} 
                          for msg in st.session_state.messages[-5:]]  # åªä¿ç•™æœ€è¿‘5æ¡æ¶ˆæ¯ä½œä¸ºä¸Šä¸‹æ–‡
                
                import asyncio
                try:
                    # ç”±äºStreamlitä¸æ”¯æŒå¼‚æ­¥ï¼Œä½¿ç”¨åŒæ­¥æ–¹å¼
                    if llm_provider == 'mock':
                        response = services['llm']._mock_response(user_input)
                    else:
                        # è¿™é‡Œéœ€è¦åŒæ­¥è°ƒç”¨API
                        response = {"content": "æŠ±æ­‰ï¼Œåœ¨Streamlitç¯å¢ƒä¸­æš‚æ—¶æ— æ³•è°ƒç”¨å¤–éƒ¨APIã€‚è¯·ä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿæ¨¡å¼ã€‚"}
                except Exception as e:
                    response = {"error": str(e)}
                
                if "error" in response:
                    ai_response = f"âŒ {response['error']}"
                else:
                    ai_response = response["content"]
                
                st.session_state.messages.append({"role": "assistant", "content": ai_response})
                st.rerun()
    
    with col2:
        st.header("ğŸ’° æŠ¥ä»·ä¸æ”¯ä»˜")
        
        # ç”ŸæˆæŠ¥ä»·
        if st.button("ğŸ“Š ç”Ÿæˆé¡¹ç›®æŠ¥ä»·"):
            quote = {
                "quote_id": str(uuid.uuid4()),
                "tasks": [
                    {
                        "name": "å›¾åƒOCRè¯†åˆ«",
                        "description": "å°†å›¾åƒä¸­çš„æ–‡å­—è¯†åˆ«å¹¶è½¬æ¢ä¸ºMarkdownæ ¼å¼",
                        "price": 50.0,
                        "estimated_time": "5-10åˆ†é’Ÿ"
                    },
                    {
                        "name": "æ–‡æœ¬è½¬è¯­éŸ³",
                        "description": "å°†æ–‡æœ¬è½¬æ¢ä¸ºé«˜è´¨é‡è¯­éŸ³æ–‡ä»¶",
                        "price": 30.0,
                        "estimated_time": "3-8åˆ†é’Ÿ"
                    }
                ],
                "total_price": 80.0,
                "currency": "CNY",
                "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
            st.session_state.project_data["quotes"].append(quote)
            st.success("âœ… æŠ¥ä»·ç”ŸæˆæˆåŠŸï¼")
        
        # æ˜¾ç¤ºæŠ¥ä»·
        if st.session_state.project_data["quotes"]:
            latest_quote = st.session_state.project_data["quotes"][-1]
            
            st.markdown(f"""
            <div class="status-card">
                <h4>ğŸ“‹ æœ€æ–°æŠ¥ä»·</h4>
                <p><strong>æŠ¥ä»·ID:</strong> {latest_quote['quote_id'][:8]}...</p>
                <p><strong>æ€»ä»·:</strong> Â¥{latest_quote['total_price']}</p>
                <p><strong>åˆ›å»ºæ—¶é—´:</strong> {latest_quote['created_at']}</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.subheader("ğŸ“ ä»»åŠ¡æ˜ç»†")
            for task in latest_quote["tasks"]:
                with st.expander(f"{task['name']} - Â¥{task['price']}"):
                    st.write(f"**æè¿°:** {task['description']}")
                    st.write(f"**é¢„ä¼°æ—¶é—´:** {task['estimated_time']}")
            
            # æ¨¡æ‹Ÿæ”¯ä»˜
            if st.button("ğŸ’³ ç¡®è®¤æ”¯ä»˜"):
                st.session_state.project_data["payment_status"] = "completed"
                st.success("âœ… æ”¯ä»˜æˆåŠŸï¼é¡¹ç›®å·²å¯åŠ¨ã€‚")
        
        # TTSåŠŸèƒ½
        st.subheader("ğŸµ æ–‡æœ¬è½¬è¯­éŸ³")
        tts_text = st.text_area("è¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬:", height=100)
        
        if st.button("ğŸ”Š ç”Ÿæˆè¯­éŸ³") and tts_text:
            with st.spinner("æ­£åœ¨ç”Ÿæˆè¯­éŸ³..."):
                if use_elevenlabs and elevenlabs_api_key:
                    tts_result = services['tts'].generate_tts_with_elevenlabs(
                        tts_text, voice_id, elevenlabs_api_key
                    )
                else:
                    tts_result = services['tts'].generate_tts_mock(tts_text, voice_id)
                
                if "error" in tts_result:
                    st.error(f"âŒ {tts_result['error']}")
                else:
                    st.success("âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸï¼")
                    
                    # æ˜¾ç¤ºTTSç»“æœ
                    if "audio_data" in tts_result:
                        st.audio(tts_result["audio_data"], format="audio/mp3")
                    
                    # æ˜¾ç¤ºQCæŠ¥å‘Š
                    if "qc_report" in tts_result:
                        qc = tts_result["qc_report"]
                        st.markdown(f"""
                        **QCè´¨é‡æŠ¥å‘Š:**
                        - æ€»åˆ†: {qc['score']}/100
                        - éŸ³é¢‘è´¨é‡: {qc['audio_quality']}/100
                        - æ–‡æœ¬å‡†ç¡®æ€§: {qc['text_accuracy']}/100
                        - è¯­éŸ³ä¸€è‡´æ€§: {qc['voice_consistency']}/100
                        """)
                    
                    # ä¿å­˜åˆ°é¡¹ç›®æ•°æ®
                    st.session_state.project_data["files"].append({
                        "type": "tts",
                        "text": tts_text,
                        "result": tts_result
                    })
    
    with col3:
        st.header("ğŸ“ˆ é¡¹ç›®è¿›åº¦")
        
        # è¿›åº¦æ—¶é—´è½´
        timeline_stages = [
            {"name": "éœ€æ±‚æ¾„æ¸…", "status": "completed", "progress": 100},
            {"name": "æŠ¥ä»·ç”Ÿæˆ", "status": "completed" if st.session_state.project_data["quotes"] else "pending", "progress": 100 if st.session_state.project_data["quotes"] else 0},
            {"name": "æ”¯ä»˜ç¡®è®¤", "status": "completed" if st.session_state.project_data.get("payment_status") == "completed" else "pending", "progress": 100 if st.session_state.project_data.get("payment_status") == "completed" else 0},
            {"name": "ä»»åŠ¡å¤„ç†", "status": "completed" if st.session_state.project_data["files"] else "pending", "progress": 100 if st.session_state.project_data["files"] else 0},
            {"name": "è´¨é‡æ£€æŸ¥", "status": "completed" if st.session_state.project_data["files"] else "pending", "progress": 100 if st.session_state.project_data["files"] else 0},
            {"name": "äº¤ä»˜å®Œæˆ", "status": "completed" if len(st.session_state.project_data["files"]) >= 2 else "pending", "progress": 100 if len(st.session_state.project_data["files"]) >= 2 else 0}
        ]
        
        for i, stage in enumerate(timeline_stages):
            if stage["status"] == "completed":
                icon = "âœ…"
                color = "#4CAF50"
            elif stage["status"] == "pending":
                icon = "â³"
                color = "#FF9800"
            else:
                icon = "â­•"
                color = "#9E9E9E"
            
            st.markdown(f"""
            <div style="display: flex; align-items: center; margin: 0.5rem 0;">
                <span style="font-size: 1.2rem; margin-right: 0.5rem;">{icon}</span>
                <span style="color: {color}; font-weight: bold;">{stage['name']}</span>
            </div>
            """, unsafe_allow_html=True)
            
            if stage["progress"] > 0:
                st.progress(stage["progress"] / 100)
        
        # é¡¹ç›®ç»Ÿè®¡
        st.subheader("ğŸ“Š é¡¹ç›®ç»Ÿè®¡")
        
        col_a, col_b = st.columns(2)
        with col_a:
            st.markdown(f"""
            <div class="metric-card">
                <h3>{len(st.session_state.project_data['files'])}</h3>
                <p>å·²å¤„ç†æ–‡ä»¶</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col_b:
            st.markdown(f"""
            <div class="metric-card">
                <h3>{len(st.session_state.project_data['quotes'])}</h3>
                <p>ç”ŸæˆæŠ¥ä»·</p>
            </div>
            """, unsafe_allow_html=True)
        
        # æ–‡ä»¶åˆ—è¡¨
        if st.session_state.project_data["files"]:
            st.subheader("ğŸ“ å¤„ç†ç»“æœ")
            for i, file_data in enumerate(st.session_state.project_data["files"]):
                with st.expander(f"{file_data['type'].upper()} - {file_data.get('filename', f'ä»»åŠ¡{i+1}')}"):
                    if file_data["type"] == "ocr":
                        st.markdown("**è¯†åˆ«æ–‡æœ¬:**")
                        st.text_area("", value=file_data["result"]["extracted_text"], height=100, disabled=True, key=f"ocr_{i}")
                        st.markdown(f"**ç½®ä¿¡åº¦:** {file_data['result']['confidence']:.2%}")
                    elif file_data["type"] == "tts":
                        st.markdown(f"**åŸæ–‡æœ¬:** {file_data['text']}")
                        if "qc_report" in file_data["result"]:
                            st.markdown(f"**è´¨é‡è¯„åˆ†:** {file_data['result']['qc_report']['score']}/100")

if __name__ == "__main__":
    main()
